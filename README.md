# Authenticated AI Inference Service (FastAPI)

A production-style **AI inference API** built with **FastAPI** that provides:
- **User registration & login**
- **JWT authentication**
- **Protected AI inference endpoint** (`/ai/predict`)
- Clean, scalable project structure designed for real-world ML systems

> Goal: build an AI Engineerâ€“level portfolio by shipping secure, deployable inference services (not notebooks).

---

## âœ… Features

### Authentication
- `POST /auth/register` â€” create a user
- `POST /auth/login` â€” login and receive an access token (JWT)
- `GET /auth/me` â€” protected route to verify token + user identity

### AI Inference
- `POST /ai/predict` â€” protected endpoint for model inference  
  *(currently supports a baseline inference implementation; upgrade path includes real model artifacts + versioning)*

---

## ğŸ›  Tech Stack
- Python
- FastAPI
- Uvicorn
- JWT (python-jose)
- Passlib (password hashing)
- python-multipart (OAuth2 form login)
- Git & GitHub

---

## ğŸ“ Project Structure

```text
app/
  main.py
  api/
    auth/
      router.py
    ai/
      router.py
      service.py
  core/
    security.py
    dependencies.py
requirements.txt
README.md
